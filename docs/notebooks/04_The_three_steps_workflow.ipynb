{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b295407-92c4-4818-bfb9-f445f6967f10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b295407-92c4-4818-bfb9-f445f6967f10",
    "outputId": "dc6c8e1b-2875-4287-d83a-4bdc4c9db80a"
   },
   "outputs": [],
   "source": [
    "# Uncomment to run the notebook in Colab\n",
    "# ! pip install -q \"wax-ml[complete]@git+https://github.com/eserie/wax-ml.git\"\n",
    "# ! pip install -q --upgrade jax jaxlib==0.1.70+cuda111 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30291d",
   "metadata": {
    "id": "ff30291d"
   },
   "outputs": [],
   "source": [
    "# check available devices\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cdb104",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3cdb104",
    "outputId": "a6f395c3-6ee3-4fe5-ce39-a02617a129ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax backend cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<jaxlib.xla_extension.Device at 0x17678ceb0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"jax backend {}\".format(jax.lib.xla_bridge.get_backend().platform))\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1808c",
   "metadata": {
    "id": "1fa1808c"
   },
   "source": [
    "# ðŸŽ› The 3-steps workflow ðŸŽ›\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/04_The_three_steps_workflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eefec",
   "metadata": {
    "id": "2e1eefec"
   },
   "source": [
    "It is already very useful to be able to execute a JAX function on a dataframe in a single work step\n",
    "and with a single command line thanks to WAX-ML accessors.\n",
    "\n",
    "The 1-step WAX-ML's stream API works like that:\n",
    "```python\n",
    "<data-container>.stream(...).apply(...)\n",
    "```\n",
    "\n",
    "But this is not optimal because, under the hood, there are mainly three costly steps:\n",
    "- (1) (synchronize | data tracing | encode): make the data \"JAX ready\"\n",
    "- (2) (compile | code tracing | execution): compile and optimize a function for XLA, execute it.\n",
    "- (3) (format): convert data back to pandas/xarray/numpy format.\n",
    "\n",
    "With the `wax.stream` primitives, it is quite easy to explicitly split the 1-step workflow\n",
    "into a 3-step workflow.\n",
    "\n",
    "This will allow the user to have full control over each step and iterate on each one.\n",
    "\n",
    "It is actually very useful to iterate on step (2), the \"calculation step\" when\n",
    "you are doing research.\n",
    "You can then take full advantage of the JAX primitives, especially the `jit` primitive.\n",
    "\n",
    "Let's illustrate how to reimplement WAX-ML EWMA yourself with the WAX-ML 3-step workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e906e",
   "metadata": {
    "id": "bd2e906e"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bdfbf9a",
   "metadata": {
    "id": "2bdfbf9a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from wax.accessors import register_wax_accessors\n",
    "from wax.external.eagerpy import convert_to_tensors\n",
    "from wax.format import format_dataframe\n",
    "from wax.modules import EWMA\n",
    "from wax.stream import tree_access_data\n",
    "from wax.unroll import unroll\n",
    "\n",
    "register_wax_accessors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0999c69",
   "metadata": {
    "id": "a0999c69"
   },
   "source": [
    "## Performance on big dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8447b4",
   "metadata": {
    "id": "6f8447b4"
   },
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768d7802-580d-4c31-9a0e-e6dc4f0589ca",
   "metadata": {
    "id": "768d7802-580d-4c31-9a0e-e6dc4f0589ca",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "T = 1.0e5\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03af743d",
   "metadata": {
    "id": "03af743d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "T, N = map(int, (T, N))\n",
    "dataframe = pd.DataFrame(\n",
    "    onp.random.normal(size=(T, N)), index=pd.date_range(\"1970\", periods=T, freq=\"s\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd46f7",
   "metadata": {
    "id": "d1fd46f7"
   },
   "source": [
    "### pandas EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27092faf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27092faf",
    "outputId": "e97a2738-5c2a-4bf9-c9e0-c44040185424",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 167 ms, total: 2.19 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ewma_pandas = dataframe.ewm(alpha=1.0 / 10.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678be283",
   "metadata": {
    "id": "678be283"
   },
   "source": [
    "### WAX-ML EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f3705d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11f3705d",
    "outputId": "744f0faa-7030-4155-80ae-4a5c745731f8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 876 ms, total: 2.68 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ewma_wax = dataframe.wax.ewm(alpha=1.0 / 10.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94d5cf",
   "metadata": {
    "id": "0d94d5cf"
   },
   "source": [
    "It's a little faster, but not that much faster..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ee290",
   "metadata": {
    "id": "e51ee290"
   },
   "source": [
    "### WAX-ML EWMA (without format step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361def9",
   "metadata": {
    "id": "7361def9"
   },
   "source": [
    "Let's disable the final formatting step (the output is now in raw JAX format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87f5668",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f87f5668",
    "outputId": "3f37d97e-1875-4f66-9e6b-9a22b20642a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 1 s, total: 2.8 s\n",
      "Wall time: 3.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-2.9661492e-01, -3.2103235e-01, -9.6144844e-03, ...,\n",
       "               4.4276214e-01,  1.1568004e+00, -1.0724162e+00],\n",
       "             [-9.5860586e-02, -2.0366390e-01, -3.7967765e-01, ...,\n",
       "              -6.1594141e-01,  7.7942121e-01,  1.8111229e-02],\n",
       "             [ 2.8211397e-01,  1.7749734e-01, -2.0034584e-01, ...,\n",
       "              -7.6095390e-01,  5.3778893e-01,  3.1442198e-01],\n",
       "             ...,\n",
       "             [-1.1917123e-01,  1.3764068e-01,  2.4761766e-01, ...,\n",
       "               2.0842913e-01,  2.5283977e-01, -1.1205430e-01],\n",
       "             [-1.0947308e-01,  3.6484647e-01,  2.4164049e-01, ...,\n",
       "               2.7038181e-01,  2.4539444e-01,  6.2920153e-05],\n",
       "             [ 4.8219025e-02,  1.5648599e-01,  1.2161890e-01, ...,\n",
       "               2.0765728e-01,  8.9837506e-02,  1.0943251e-01]],            dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_ewma_wax_no_format = dataframe.wax.ewm(alpha=1.0 / 10.0, format_outputs=False).mean()\n",
    "df_ewma_wax_no_format.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d0cab5-62ad-47f7-9d06-56fc45fa542e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88d0cab5-62ad-47f7-9d06-56fc45fa542e",
    "outputId": "f8b7c4fb-79a7-4652-82eb-2b649aeb074c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.DeviceArray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_ewma_wax_no_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be62475-b2fa-4a95-b293-7e4410ca36ca",
   "metadata": {
    "id": "9be62475-b2fa-4a95-b293-7e4410ca36ca"
   },
   "source": [
    "Let's check the device on which the calculation was performed (if you have GPU available, this should be `GpuDevice` otherwise it will be `CpuDevice`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d3970c-04a5-4deb-93b3-a4f5f899e8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d3970c-04a5-4deb-93b3-a4f5f899e8f1",
    "outputId": "ba287d55-719a-47de-f959-9223effbe7a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ewma_wax_no_format.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ee16e",
   "metadata": {
    "id": "784ee16e"
   },
   "source": [
    "Now we will see how to break down WAX-ML one-liners `<dataset>.ewm(...).mean()` or `<dataset>.stream(...).apply(...)` into 3 steps:\n",
    "- a preparation step where we prepare JAX-ready data and functions.\n",
    "- a processing step where we execute the JAX program\n",
    "- a post-processing step where we format the results in pandas or xarray format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7b817",
   "metadata": {
    "id": "c5e7b817"
   },
   "source": [
    "### Generate data (in dataset format)\n",
    "\n",
    "WAX-ML `Sream` object works on datasets.\n",
    "So let's transform the `DataFrame` into a xarray `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9965444b",
   "metadata": {
    "id": "9965444b"
   },
   "outputs": [],
   "source": [
    "dataset = xr.DataArray(dataframe).to_dataset(name=\"dataarray\")\n",
    "del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123965eb",
   "metadata": {
    "id": "123965eb"
   },
   "source": [
    "## Step (1) (synchronize | data tracing | encode)\n",
    "\n",
    "In this step,  WAX-ML do:\n",
    "- \"data tracing\" : prepare the indices for fast access tin the JAX function `access_data`\n",
    "- synchronize streams if there is multiple ones.\n",
    "  This functionality have options : `freq`, `ffills`\n",
    "- encode and convert data from numpy to JAX: use encoders for `datetimes64` and `string_`\n",
    "  dtypes. Be aware that by default JAX works in float32\n",
    "  (see [JAX's Common Gotchas](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision) to work in float64).\n",
    "\n",
    "We have a function `Stream.prepare` that implement this Step (1).\n",
    "It prepares a function that wraps the input function with the actual data and indices\n",
    "in a pair of pure functions (`TransformedWithState` Haiku tuple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f6b72ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f6b72ca",
    "lines_to_next_cell": 1,
    "outputId": "e6852b1f-65bb-478a-ea6f-1cc6a3ce0898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 Âµs, sys: 36 Âµs, total: 280 Âµs\n",
      "Wall time: 287 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stream = dataset.wax.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc34aad-3e15-4220-9dff-30dcad660307",
   "metadata": {
    "id": "4cc34aad-3e15-4220-9dff-30dcad660307",
    "lines_to_next_cell": 2
   },
   "source": [
    "Define our custom function to be applied on a dict of arrays\n",
    "having the same structure than the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfa2a6c",
   "metadata": {
    "id": "2bfa2a6c",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def my_ewma_on_dataset(dataset):\n",
    "    return EWMA(alpha=1.0 / 10.0, adjust=True)(dataset[\"dataarray\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4735903f",
   "metadata": {
    "id": "4735903f"
   },
   "outputs": [],
   "source": [
    "transform_dataset, jxs = stream.prepare(dataset, my_ewma_on_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b31346-501a-407b-b586-780117d043f3",
   "metadata": {
    "id": "18b31346-501a-407b-b586-780117d043f3",
    "lines_to_next_cell": 2
   },
   "source": [
    "Let's definite the init parameters and state of the transformation we\n",
    "will apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a778c",
   "metadata": {
    "id": "903a778c"
   },
   "source": [
    "## Step (2) (compile | code tracing | execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425830f4",
   "metadata": {
    "id": "425830f4"
   },
   "source": [
    "In this step we:\n",
    "- prepare a pure function (with\n",
    "  [Haiku's transform mechanism](https://dm-haiku.readthedocs.io/en/latest/api.html#haiku-transforms))\n",
    "  Define a \"transformation\" function which:\n",
    "    - access to the data\n",
    "    - apply another transformation, here: EWMA\n",
    "\n",
    "- compile it with `jax.jit`\n",
    "- perform code tracing and execution (the last line):\n",
    "    - Unroll the transformation on \"steps\" `xs` (a `np.arange` vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6825fdc8-1773-4e04-a41c-a126a1527891",
   "metadata": {
    "id": "6825fdc8-1773-4e04-a41c-a126a1527891"
   },
   "outputs": [],
   "source": [
    "outputs = unroll(transform_dataset)(jxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3862a486-a5a2-4aa9-967a-59ebc32a18e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3862a486-a5a2-4aa9-967a-59ebc32a18e1",
    "outputId": "b54b4e2c-a0ab-4a43-d331-d6b3d90707c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f3252",
   "metadata": {
    "id": "b73f3252"
   },
   "source": [
    "Once it has been compiled and \"traced\" by JAX, the function is much faster to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a889d294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a889d294",
    "outputId": "e69a75ff-4b00-4a1d-f101-49944e01d9b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619 ms Â± 9.49 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "outputs = unroll(transform_dataset)(jxs)\n",
    "_ = outputs.block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e8b63",
   "metadata": {
    "id": "987e8b63"
   },
   "source": [
    "This is 3x faster than pandas implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8acec1-4414-4340-9cfc-199e90565d4d",
   "metadata": {
    "id": "4c8acec1-4414-4340-9cfc-199e90565d4d"
   },
   "source": [
    "### Manually prepare the data and manage the device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76775b-76f7-45ae-8bc7-66a6f945370f",
   "metadata": {
    "id": "8b76775b-76f7-45ae-8bc7-66a6f945370f"
   },
   "source": [
    "In order to manage the device on which the computations take place,\n",
    "we need to have even more control over the execution flow.\n",
    "Instead of calling `stream.prepare` to build the `transform_dataset` function,\n",
    "we can do it ourselves by :\n",
    "- using the `stream.trace_dataset` function\n",
    "- converting the numpy data in jax ourself\n",
    "- puting the data on the device we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76479f76-7b6e-4321-97c3-942f2987bc01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76479f76-7b6e-4321-97c3-942f2987bc01",
    "outputId": "7f22f580-be0b-4d23-9d4d-7d89c9dd117b"
   },
   "outputs": [],
   "source": [
    "np_data, np_index, xs = stream.trace_dataset(dataset)\n",
    "jnp_data, jnp_index, jxs = convert_to_tensors((np_data, np_index, xs), \"jax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa1934-3633-4661-b808-c60e4b8c4600",
   "metadata": {
    "id": "a4fa1934-3633-4661-b808-c60e4b8c4600"
   },
   "source": [
    "We explicitly set data on CPUs (the is not needed if you only have CPUs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae591f7-e7ec-4b8b-9b80-6f129184e1ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bae591f7-e7ec-4b8b-9b80-6f129184e1ae",
    "outputId": "36f15d54-170f-4771-f571-ecacbc942026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data copied to CPU device.\n"
     ]
    }
   ],
   "source": [
    "from jax.tree_util import tree_leaves, tree_map\n",
    "\n",
    "cpus = jax.devices(\"cpu\")\n",
    "jnp_data, jnp_index, jxs = tree_map(\n",
    "    lambda x: jax.device_put(x, cpus[0]), (jnp_data, jnp_index, jxs)\n",
    ")\n",
    "print(\"data copied to CPU device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851fbe7-096e-4399-ae5c-08739837dfeb",
   "metadata": {
    "id": "f851fbe7-096e-4399-ae5c-08739837dfeb"
   },
   "source": [
    "We have now \"JAX-ready\" data for later fast access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3b58e-61f3-481c-a512-cb87bde622a8",
   "metadata": {
    "id": "19f3b58e-61f3-481c-a512-cb87bde622a8"
   },
   "source": [
    "Let's define the transformation that wrap the actual data and indices in a pair of\n",
    "pure functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7ebbb08-d790-4977-b49d-c9224e299a42",
   "metadata": {
    "id": "e7ebbb08-d790-4977-b49d-c9224e299a42"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@unroll\n",
    "def transform_dataset(step):\n",
    "    dataset = tree_access_data(jnp_data, jnp_index, step)\n",
    "    return EWMA(alpha=1.0 / 10.0, adjust=True)(dataset[\"dataarray\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa1d05-c3d7-4543-ac82-d398044cdc2e",
   "metadata": {
    "id": "31fa1d05-c3d7-4543-ac82-d398044cdc2e"
   },
   "source": [
    "And we can call it as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f851407a-597f-4711-8370-c3e83cb50da7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f851407a-597f-4711-8370-c3e83cb50da7",
    "outputId": "3892357f-2d91-40b6-85bc-542e471ed28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 1.06 s, total: 2.78 s\n",
      "Wall time: 3.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = transform_dataset(jxs)\n",
    "_ = outputs.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cd5a720",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f851407a-597f-4711-8370-c3e83cb50da7",
    "outputId": "3892357f-2d91-40b6-85bc-542e471ed28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 546 ms, sys: 52.8 ms, total: 599 ms\n",
      "Wall time: 567 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = transform_dataset(jxs)\n",
    "_ = outputs.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5b786b7-ecaf-4280-894b-aa8f65a0b78f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5b786b7-ecaf-4280-894b-aa8f65a0b78f",
    "outputId": "2e3c126e-9c9d-49b4-caa5-67f215944188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa51498",
   "metadata": {
    "id": "6fa51498"
   },
   "source": [
    "## Step(3) (format)\n",
    "Let's come back to pandas/xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1b0732c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1b0732c",
    "outputId": "38e747c5-5b1c-40dc-c289-5aeebe503a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 ms, sys: 70.4 ms, total: 98.2 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = format_dataframe(\n",
    "    dataset.coords, onp.array(outputs), format_dims=dataset.dataarray.dims\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27bd3b8",
   "metadata": {
    "id": "e27bd3b8"
   },
   "source": [
    "It's quite slow (see WEP3 enhancement proposal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc9281-6092-4368-a0e8-ed26a5114106",
   "metadata": {
    "id": "3cdc9281-6092-4368-a0e8-ed26a5114106"
   },
   "source": [
    "## GPU execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4651d-9087-4f04-9f07-a4d92cd3ba1f",
   "metadata": {
    "id": "f0d4651d-9087-4f04-9f07-a4d92cd3ba1f"
   },
   "source": [
    "Let's look with execution on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a30f6024-5e9c-4174-92ea-7207860d829d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a30f6024-5e9c-4174-92ea-7207860d829d",
    "outputId": "95058ee2-9461-4e7e-f9b1-b1e55087dc9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested backend gpu, but it failed to initialize: Not found: Could not find registered platform with name: \"cuda\". Available platform names are: Interpreter Host\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gpus = jax.devices(\"gpu\")\n",
    "    jnp_data, jnp_index, jxs = tree_map(\n",
    "        lambda x: jax.device_put(x, gpus[0]), (jnp_data, jnp_index, jxs)\n",
    "    )\n",
    "    print(\"data copied to GPU device.\")\n",
    "    GPU_AVAILABLE = True\n",
    "except RuntimeError as err:\n",
    "    print(err)\n",
    "    GPU_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7cf26-f35b-489e-83b9-c120565d9b17",
   "metadata": {
    "id": "27d7cf26-f35b-489e-83b9-c120565d9b17"
   },
   "source": [
    "Let's check that our data is on the GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6f00e5d-1b85-483d-9856-35de3a954b13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6f00e5d-1b85-483d-9856-35de3a954b13",
    "outputId": "9d5d0ec1-4899-4d8e-d9f6-2232321ec42a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_leaves(jnp_data)[0].device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f89fc7c-4824-4858-aee8-6fff7834c70c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f89fc7c-4824-4858-aee8-6fff7834c70c",
    "outputId": "5b5304de-0694-4944-92f1-63eee852ebf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_leaves(jnp_index)[0].device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba2471ef-51e4-49f2-863c-aabafd401cbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba2471ef-51e4-49f2-863c-aabafd401cbf",
    "outputId": "e6afa394-3e1b-4b9b-aea6-9dfe0d60ab86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jxs.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c35bd5d-0113-455d-bd56-f7c31bf6c736",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c35bd5d-0113-455d-bd56-f7c31bf6c736",
    "lines_to_next_cell": 2,
    "outputId": "fda693e8-723e-436d-84f6-68a49a510be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 2 Âµs, total: 5 Âµs\n",
      "Wall time: 11.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if GPU_AVAILABLE:\n",
    "    outputs = unroll(transform_dataset)(jxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b5615-8785-43e7-a2db-5f867566c913",
   "metadata": {
    "id": "274b5615-8785-43e7-a2db-5f867566c913"
   },
   "source": [
    "Let's redefine our function `transform_dataset` by explicitly specify to `jax.jit` the `device` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bb7431e-90f2-4761-a906-69f25fea4a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bb7431e-90f2-4761-a906-69f25fea4a63",
    "outputId": "285660f2-8379-4b8f-f89f-9f5a7240c419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 Âµs, sys: 2 Âµs, total: 10 Âµs\n",
      "Wall time: 15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "\n",
    "    @partial(jax.jit, device=gpus[0])\n",
    "    @unroll\n",
    "    def transform_dataset(step):\n",
    "        dataset = tree_access_data(jnp_data, jnp_index, step)\n",
    "        return EWMA(alpha=1.0 / 10.0, adjust=True)(dataset[\"dataarray\"])\n",
    "\n",
    "    outputs = transform_dataset(jxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "944dcb8e-211c-4b39-b854-12118fe775ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "944dcb8e-211c-4b39-b854-12118fe775ed",
    "outputId": "fbeeab1e-e245-4d85-ad5c-09530ec7d331"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jaxlib.xla_extension.Device at 0x17678ceb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de99ee71-4e02-4843-9e6e-39d831f9697e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de99ee71-4e02-4843-9e6e-39d831f9697e",
    "lines_to_next_cell": 0,
    "outputId": "4262991e-c488-4296-849d-b111e288c203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ns Â± 0.0839 ns per loop (mean Â± std. dev. of 7 runs, 100000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "if GPU_AVAILABLE:\n",
    "    outputs = unroll(transform_dataset)(jxs)\n",
    "    _ = outputs.block_until_ready()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "04_The_three_steps_workflow.ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
