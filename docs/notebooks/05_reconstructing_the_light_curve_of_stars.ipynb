{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”­ Reconstructing the light curve of stars ðŸ”­\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/05_reconstructing_the_light_curve_of_stars.ipynb)\n",
    "In Colab install wax by executing this line in a cell:\n",
    "```python\n",
    "! pip install \"wax-ml[dev,complete] @ git+https://github.com/eserie/wax-ml.git\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a walk through the stars...\n",
    "\n",
    "This notebook is based on the study done in\n",
    "[this post by Christophe Pere](https://towardsdatascience.com/how-to-use-deep-learning-for-time-series-forecasting-3f8a399cf205)\n",
    "and the notebook available on\n",
    "[the authors's github](https://github.com/Christophe-pere/Time_series_RNN).\n",
    "\n",
    "We will repeat this study on starlight using the LSTM architecture to predict the observed light flux through time.\n",
    "\n",
    "Our LSTM implementation is based on this [notebook from Haiku's github repository](https://github.com/deepmind/dm-haiku/blob/master/examples/haiku_lstms.ipynb).\n",
    "\n",
    "We will see how to use WAX to facilitate the preparation of time series data stored in dataframes and having Nans\n",
    "before calling a \"standard\" deep-learning workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from wax.accessors import register_wax_accessors\n",
    "from wax.modules import RollingMean\n",
    "\n",
    "register_wax_accessors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "STAR = \"007609553\"\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 8\n",
    "TRAIN_STEPS = 2 ** 16\n",
    "TRAIN_SIZE = 2 ** 16\n",
    "TOTAL_LEN = None\n",
    "TRAIN_DATE = \"2016\"\n",
    "CACHE_DIR = Path(\"./cached_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved in cached_data/kep_lightcurves.parquet\n",
      "CPU times: user 1.2 s, sys: 181 ms, total: 1.38 s\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = CACHE_DIR / \"kep_lightcurves.parquet\"\n",
    "try:\n",
    "    raw_dataframe = pd.read_parquet(open(filename, \"rb\"))\n",
    "    # set date index\n",
    "    raw_dataframe.index = pd.Index(\n",
    "        pd.date_range(\"2009-03-07\", periods=len(raw_dataframe.index), freq=\"h\"),\n",
    "        name=\"time\",\n",
    "    )\n",
    "    print(f\"data read from {filename}\")\n",
    "except FileNotFoundError:\n",
    "    # Downloading the csv file from Chrustioge Pere GitHub account\n",
    "    download = requests.get(\n",
    "        \"https://raw.github.com/Christophe-pere/Time_series_RNN/master/kep_lightcurves.csv\"\n",
    "    ).content\n",
    "    raw_dataframe = pd.read_csv(io.StringIO(download.decode(\"utf-8\")))\n",
    "\n",
    "    # save dataframe locally in CACHE_DIR\n",
    "    CACHE_DIR.mkdir(exist_ok=True)\n",
    "    raw_dataframe.to_parquet(filename)\n",
    "    print(f\"data saved in {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# shortening of data to speed up the execution of the notebook in the CI\n",
    "if TOTAL_LEN:\n",
    "    raw_dataframe = raw_dataframe.iloc[:TOTAL_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the description of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: 'â–º';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: 'â–¼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (index: 52)\n",
       "Coordinates:\n",
       "  * index    (index) object &#x27;001430305_orig&#x27; ... &#x27;011611275_res&#x27;\n",
       "Data variables:\n",
       "    count    (index) float64 6.48e+04 5.674e+04 ... 5.673e+04 5.673e+04\n",
       "    mean     (index) float64 6.776e+04 -0.2265 0.01231 ... 0.001437 0.004351\n",
       "    std      (index) float64 1.363e+03 15.42 15.27 12.45 ... 4.648 6.415 4.904\n",
       "    min      (index) float64 6.529e+04 -123.3 -75.59 ... -20.32 -31.97 -20.89\n",
       "    25%      (index) float64 6.619e+04 -9.488 -9.875 ... -3.269 -4.281 -3.279\n",
       "    50%      (index) float64 6.806e+04 -0.3476 0.007812 ... 0.007812 -0.06529\n",
       "    75%      (index) float64 6.882e+04 8.988 10.02 8.092 ... 2.872 4.277 3.213\n",
       "    max      (index) float64 7.021e+04 128.7 72.31 69.34 ... 26.53 30.94 29.45</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-a85ae962-8835-4945-84a6-25fee46fe468' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-a85ae962-8835-4945-84a6-25fee46fe468' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>index</span>: 52</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-33b29acd-602e-4787-a3ef-b7bdcfe2ca56' class='xr-section-summary-in' type='checkbox'  checked><label for='section-33b29acd-602e-4787-a3ef-b7bdcfe2ca56' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>index</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;001430305_orig&#x27; ... &#x27;011611275_...</div><input id='attrs-bed485c4-6060-46ac-9c11-765457a96a5e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bed485c4-6060-46ac-9c11-765457a96a5e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2f0ff94a-6a24-4580-8d0b-92d523be57b3' class='xr-var-data-in' type='checkbox'><label for='data-2f0ff94a-6a24-4580-8d0b-92d523be57b3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;001430305_orig&#x27;, &#x27;001430305_rscl&#x27;, &#x27;001430305_diff&#x27;, &#x27;001430305_res&#x27;,\n",
       "       &#x27;001724719_orig&#x27;, &#x27;001724719_rscl&#x27;, &#x27;001724719_diff&#x27;, &#x27;001724719_res&#x27;,\n",
       "       &#x27;005209845_orig&#x27;, &#x27;005209845_rscl&#x27;, &#x27;005209845_diff&#x27;, &#x27;005209845_res&#x27;,\n",
       "       &#x27;007596240_orig&#x27;, &#x27;007596240_rscl&#x27;, &#x27;007596240_diff&#x27;, &#x27;007596240_res&#x27;,\n",
       "       &#x27;007609553_orig&#x27;, &#x27;007609553_rscl&#x27;, &#x27;007609553_diff&#x27;, &#x27;007609553_res&#x27;,\n",
       "       &#x27;008241079_orig&#x27;, &#x27;008241079_rscl&#x27;, &#x27;008241079_diff&#x27;, &#x27;008241079_res&#x27;,\n",
       "       &#x27;008247770_orig&#x27;, &#x27;008247770_rscl&#x27;, &#x27;008247770_diff&#x27;, &#x27;008247770_res&#x27;,\n",
       "       &#x27;009345933_orig&#x27;, &#x27;009345933_rscl&#x27;, &#x27;009345933_diff&#x27;, &#x27;009345933_res&#x27;,\n",
       "       &#x27;009347009_orig&#x27;, &#x27;009347009_rscl&#x27;, &#x27;009347009_diff&#x27;, &#x27;009347009_res&#x27;,\n",
       "       &#x27;009349482_orig&#x27;, &#x27;009349482_rscl&#x27;, &#x27;009349482_diff&#x27;, &#x27;009349482_res&#x27;,\n",
       "       &#x27;009349757_orig&#x27;, &#x27;009349757_rscl&#x27;, &#x27;009349757_diff&#x27;, &#x27;009349757_res&#x27;,\n",
       "       &#x27;010024701_orig&#x27;, &#x27;010024701_rscl&#x27;, &#x27;010024701_diff&#x27;, &#x27;010024701_res&#x27;,\n",
       "       &#x27;011611275_orig&#x27;, &#x27;011611275_rscl&#x27;, &#x27;011611275_diff&#x27;, &#x27;011611275_res&#x27;],\n",
       "      dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-a1554999-d211-4403-b2bc-949a3af1d8b7' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a1554999-d211-4403-b2bc-949a3af1d8b7' class='xr-section-summary' >Data variables: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>count</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.48e+04 5.674e+04 ... 5.673e+04</div><input id='attrs-050e5a9e-e8c9-47c2-a946-65ceb0fc9547' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-050e5a9e-e8c9-47c2-a946-65ceb0fc9547' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-77c887f3-0514-457c-a841-44a7b3251d2a' class='xr-var-data-in' type='checkbox'><label for='data-77c887f3-0514-457c-a841-44a7b3251d2a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([64795., 56736., 50906., 50906., 64795., 59620., 55595., 55595.,\n",
       "       54969., 49817., 45968., 45968., 64792., 60090., 56475., 56475.,\n",
       "       64793., 50829., 45782., 45782., 64794., 54544., 50508., 50508.,\n",
       "       64793., 58882., 54562., 54562., 64797., 60963., 58136., 58136.,\n",
       "       64793., 60579., 57363., 57363., 64793., 61021., 58217., 58217.,\n",
       "       64793., 60789., 57793., 57793., 51732., 47598., 44189., 44189.,\n",
       "       64792., 60245., 56728., 56728.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>mean</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.776e+04 -0.2265 ... 0.004351</div><input id='attrs-dac15903-2fd6-40e9-97ab-c4a8feaa5e17' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-dac15903-2fd6-40e9-97ab-c4a8feaa5e17' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-653b9c69-0729-4a83-b185-4ec714c0f6bf' class='xr-var-data-in' type='checkbox'><label for='data-653b9c69-0729-4a83-b185-4ec714c0f6bf' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 6.77637640e+04, -2.26476394e-01,  1.23063833e-02,  4.76521496e-02,\n",
       "        3.48858739e+04, -2.60434079e-01, -6.42200288e-04,  8.80227557e-03,\n",
       "        5.39107577e+03,  7.03697184e-03, -1.60903054e-02, -2.92293746e-02,\n",
       "        1.63334514e+04, -1.51960427e-01, -8.43860668e-03, -1.19774483e-02,\n",
       "        2.13926602e+04, -4.33682072e-01,  8.27861864e-03,  9.57967429e-03,\n",
       "        5.67090880e+04, -3.64663429e-01, -2.67114244e-03,  6.54392308e-03,\n",
       "        2.91100849e+04, -8.32231802e-02, -3.71574138e-03, -2.05330738e-02,\n",
       "        7.19740760e+03, -3.04019017e-02, -7.65547327e-04,  1.39132462e-03,\n",
       "        7.52192300e+03, -1.21187104e-01,  9.12380197e-03,  1.61813028e-02,\n",
       "        8.94735741e+03, -9.96904951e-02,  4.80096959e-03,  1.14104920e-02,\n",
       "        1.17224306e+04, -1.00470553e-01,  9.67554394e-03,  2.29960238e-02,\n",
       "        6.68149138e+04, -1.87700299e-01, -1.28047280e-02, -6.32266111e-03,\n",
       "        1.29621460e+04, -1.57874003e-01,  1.43721396e-03,  4.35098594e-03])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>std</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.363e+03 15.42 ... 6.415 4.904</div><input id='attrs-115e08ef-a470-43ab-bbe1-045fac66efc4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-115e08ef-a470-43ab-bbe1-045fac66efc4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1efa1aa3-b203-430d-9b2e-ad175ded7af3' class='xr-var-data-in' type='checkbox'><label for='data-1efa1aa3-b203-430d-9b2e-ad175ded7af3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1362.5144182 ,   15.42150384,   15.27052111,   12.44643235,\n",
       "       1528.19752763,   10.91976669,   11.1893542 ,    8.62113287,\n",
       "        204.78780872,   20.19896883,    5.84919971,    4.6135537 ,\n",
       "        535.20007192,    4.91307619,    6.8001509 ,    5.21149265,\n",
       "        660.12491961,  153.47838423,    7.95784752,    6.83305069,\n",
       "        999.65408025,   15.75699475,   11.27259006,    8.82762192,\n",
       "        893.28598443,   11.31868477,    9.1138139 ,    7.4161203 ,\n",
       "        432.80513443,   21.70344223,    5.70210104,    4.54982055,\n",
       "        179.82292187,   19.17226962,    5.43930877,    4.37342724,\n",
       "        177.04591928,    4.67562213,    6.00262878,    4.61455226,\n",
       "        272.81579415,   11.3153307 ,    6.40128184,    5.00633304,\n",
       "       2252.26388443,   89.94131559,   11.75971874,   10.21930995,\n",
       "        325.0546655 ,    4.64757018,    6.4154822 ,    4.9035335 ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>min</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.529e+04 -123.3 ... -31.97 -20.89</div><input id='attrs-90033da3-66af-4dd6-840e-0728e26912de' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-90033da3-66af-4dd6-840e-0728e26912de' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-83eec671-38b7-4f61-89ee-d9e2ddc83d3c' class='xr-var-data-in' type='checkbox'><label for='data-83eec671-38b7-4f61-89ee-d9e2ddc83d3c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 6.52850664e+04, -1.23261443e+02, -7.55937500e+01, -5.81310419e+01,\n",
       "        3.19670938e+04, -6.66089800e+01, -5.55937500e+01, -3.80387838e+01,\n",
       "        4.95582812e+03, -9.06898032e+01, -3.17832031e+01, -2.36347987e+01,\n",
       "        1.54332500e+04, -3.66425336e+01, -3.57548828e+01, -3.61389287e+01,\n",
       "        2.00126504e+04, -6.94903224e+02, -3.80410156e+01, -3.14954085e+01,\n",
       "        5.48705469e+04, -8.74110917e+01, -5.62773438e+01, -5.71788510e+01,\n",
       "        2.72978945e+04, -6.94690785e+01, -4.73476562e+01, -3.98079267e+01,\n",
       "        6.30219580e+03, -1.03889194e+02, -3.24965820e+01, -2.49301202e+01,\n",
       "        7.22198877e+03, -8.07118370e+01, -2.76318359e+01, -1.87084745e+01,\n",
       "        8.58008008e+03, -2.36194950e+01, -2.88779297e+01, -2.23368082e+01,\n",
       "        1.11858164e+04, -6.24034405e+01, -3.32412109e+01, -2.65777562e+01,\n",
       "        6.34323672e+04, -3.55021741e+02, -5.77968750e+01, -7.86537031e+01,\n",
       "        1.23135605e+04, -2.03195390e+01, -3.19687500e+01, -2.08865991e+01])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>25%</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.619e+04 -9.488 ... -4.281 -3.279</div><input id='attrs-e7c1a25a-c5df-4aab-ba12-6d9fe3fffa43' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e7c1a25a-c5df-4aab-ba12-6d9fe3fffa43' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2916ca9b-1066-4c55-b9bb-1a3c7026b247' class='xr-var-data-in' type='checkbox'><label for='data-2916ca9b-1066-4c55-b9bb-1a3c7026b247' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 6.61889219e+04, -9.48833642e+00, -9.87500000e+00, -8.08656653e+00,\n",
       "        3.32582266e+04, -7.31995398e+00, -7.44335938e+00, -5.79592451e+00,\n",
       "        5.18955225e+03, -9.56397223e+00, -3.89270020e+00, -3.11812362e+00,\n",
       "        1.58437983e+04, -3.44825902e+00, -4.50830078e+00, -3.52359963e+00,\n",
       "        2.07200391e+04, -7.54642556e+01, -5.27343750e+00, -4.56884892e+00,\n",
       "        5.59803770e+04, -1.02040155e+01, -7.57812500e+00, -5.93617727e+00,\n",
       "        2.81871973e+04, -7.12718836e+00, -6.01953125e+00, -4.90452721e+00,\n",
       "        6.65427344e+03, -1.23264574e+01, -3.74560547e+00, -3.03522067e+00,\n",
       "        7.42203711e+03, -1.13228045e+01, -3.61962891e+00, -2.91987469e+00,\n",
       "        8.78827148e+03, -3.17652362e+00, -3.98632812e+00, -3.08491497e+00,\n",
       "        1.15134297e+04, -6.10318459e+00, -4.21875000e+00, -3.29996354e+00,\n",
       "        6.49962314e+04, -5.62104609e+01, -7.89062500e+00, -6.86189833e+00,\n",
       "        1.28410632e+04, -3.26949598e+00, -4.28125000e+00, -3.27908045e+00])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>50%</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.806e+04 -0.3476 ... -0.06529</div><input id='attrs-5f7e1a27-64e7-4208-a57e-9e4c182c4de6' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5f7e1a27-64e7-4208-a57e-9e4c182c4de6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f01ecabb-d143-4c1e-a2f1-6ad1c6ac6367' class='xr-var-data-in' type='checkbox'><label for='data-f01ecabb-d143-4c1e-a2f1-6ad1c6ac6367' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 6.80613828e+04, -3.47636218e-01,  7.81250000e-03, -1.30725999e-02,\n",
       "        3.53564023e+04, -9.16894810e-02, -3.51562500e-02, -2.89893356e-02,\n",
       "        5.41613721e+03,  1.46219949e-01, -5.78613281e-02, -9.43597722e-02,\n",
       "        1.65516709e+04, -2.64416689e-01,  2.73437500e-02, -9.33119760e-02,\n",
       "        2.14401523e+04,  1.14545608e+01,  2.14843750e-02, -5.92623226e-02,\n",
       "        5.67837734e+04,  8.92652675e-02,  1.95312500e-03, -7.25704027e-02,\n",
       "        2.95458281e+04,  4.87577712e-02, -4.49218750e-02, -1.00367284e-01,\n",
       "        7.25929248e+03, -2.94537715e-01,  3.34472656e-02, -2.26939366e-02,\n",
       "        7.45421924e+03, -3.65075272e-01, -1.66015625e-02, -4.78969335e-02,\n",
       "        8.95055371e+03, -1.40979344e-01,  7.81250000e-03, -1.58822255e-02,\n",
       "        1.16602783e+04,  2.74758582e-01,  2.73437500e-02, -4.15869687e-02,\n",
       "        6.58943555e+04,  3.32494254e+00,  4.68750000e-02, -5.63888776e-02,\n",
       "        1.29597114e+04, -2.24671520e-01,  7.81250000e-03, -6.52851501e-02])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>75%</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.882e+04 8.988 ... 4.277 3.213</div><input id='attrs-fa8f9e85-c08d-48aa-a6ad-17200a9a9573' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fa8f9e85-c08d-48aa-a6ad-17200a9a9573' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b4ce5bd9-abce-49cb-b99d-6523fafe34dc' class='xr-var-data-in' type='checkbox'><label for='data-b4ce5bd9-abce-49cb-b99d-6523fafe34dc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([6.88189727e+04, 8.98839136e+00, 1.00234375e+01, 8.09175077e+00,\n",
       "       3.61145820e+04, 7.01429305e+00, 7.48437500e+00, 5.69826563e+00,\n",
       "       5.53317725e+03, 1.00475793e+01, 3.87048340e+00, 2.98923215e+00,\n",
       "       1.68310957e+04, 3.02806213e+00, 4.49414062e+00, 3.38630625e+00,\n",
       "       2.20209531e+04, 9.08799796e+01, 5.26367188e+00, 4.52717869e+00,\n",
       "       5.74483965e+04, 1.01837346e+01, 7.51171875e+00, 5.81439607e+00,\n",
       "       2.99188320e+04, 7.15369426e+00, 6.00732422e+00, 4.81928542e+00,\n",
       "       7.52007275e+03, 1.29233935e+01, 3.76867676e+00, 2.95097962e+00,\n",
       "       7.65798096e+03, 1.08133591e+01, 3.61523438e+00, 2.87012749e+00,\n",
       "       9.08583008e+03, 2.94619654e+00, 3.98046875e+00, 3.03713233e+00,\n",
       "       1.19144434e+04, 6.53949167e+00, 4.25976562e+00, 3.31653085e+00,\n",
       "       6.81768262e+04, 5.91546280e+01, 7.77343750e+00, 6.74722831e+00,\n",
       "       1.31409404e+04, 2.87210558e+00, 4.27661133e+00, 3.21300974e+00])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>max</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>7.021e+04 128.7 ... 30.94 29.45</div><input id='attrs-57ffe94d-315b-4dc3-ba55-89014434a232' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-57ffe94d-315b-4dc3-ba55-89014434a232' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e457fbfd-91a5-45b8-8629-d494b11553f3' class='xr-var-data-in' type='checkbox'><label for='data-e457fbfd-91a5-45b8-8629-d494b11553f3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([7.02122031e+04, 1.28660432e+02, 7.23125000e+01, 6.93417611e+01,\n",
       "       3.75573242e+04, 4.79886762e+01, 8.00234375e+01, 6.16484304e+01,\n",
       "       6.00489502e+03, 9.13358716e+01, 2.45039062e+01, 2.61494406e+01,\n",
       "       1.73261172e+04, 2.35996818e+01, 3.72900391e+01, 2.62028292e+01,\n",
       "       2.24849180e+04, 3.82495214e+02, 3.95625000e+01, 3.61686737e+01,\n",
       "       5.90490898e+04, 7.62124556e+01, 5.41562500e+01, 5.42089099e+01,\n",
       "       3.03895098e+04, 6.19293590e+01, 4.28691406e+01, 4.45521063e+01,\n",
       "       7.83280371e+03, 7.73476225e+01, 2.73188477e+01, 2.46408888e+01,\n",
       "       8.00235156e+03, 6.99670019e+01, 3.19765625e+01, 2.73471557e+01,\n",
       "       9.59054297e+03, 2.72015177e+01, 2.51455078e+01, 2.51618206e+01,\n",
       "       1.22767207e+04, 4.38635401e+01, 3.68515625e+01, 3.04471056e+01,\n",
       "       7.25150000e+04, 3.21070047e+02, 6.51328125e+01, 5.87010158e+01,\n",
       "       1.39579814e+04, 2.65332384e+01, 3.09394531e+01, 2.94483002e+01])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-315ff8d0-9ba9-489c-9c2e-943411ce5d79' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-315ff8d0-9ba9-489c-9c2e-943411ce5d79' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (index: 52)\n",
       "Coordinates:\n",
       "  * index    (index) object '001430305_orig' ... '011611275_res'\n",
       "Data variables:\n",
       "    count    (index) float64 6.48e+04 5.674e+04 ... 5.673e+04 5.673e+04\n",
       "    mean     (index) float64 6.776e+04 -0.2265 0.01231 ... 0.001437 0.004351\n",
       "    std      (index) float64 1.363e+03 15.42 15.27 12.45 ... 4.648 6.415 4.904\n",
       "    min      (index) float64 6.529e+04 -123.3 -75.59 ... -20.32 -31.97 -20.89\n",
       "    25%      (index) float64 6.619e+04 -9.488 -9.875 ... -3.269 -4.281 -3.279\n",
       "    50%      (index) float64 6.806e+04 -0.3476 0.007812 ... 0.007812 -0.06529\n",
       "    75%      (index) float64 6.882e+04 8.988 10.02 8.092 ... 2.872 4.277 3.213\n",
       "    max      (index) float64 7.021e+04 128.7 72.31 69.34 ... 26.53 30.94 29.45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataframe.describe().T.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of stars available is: 13\n",
      "star identifiers: ['001430305', '001724719', '005209845', '007596240', '007609553', '008241079', '008247770', '009345933', '009347009', '009349482', '009349757', '010024701', '011611275']\n"
     ]
    }
   ],
   "source": [
    "stars = raw_dataframe.columns\n",
    "stars = sorted(list(set([i.split(\"_\")[0] for i in stars])))\n",
    "print(f\"The number of stars available is: {len(stars)}\")\n",
    "print(f\"star identifiers: {stars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71427, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = raw_dataframe[[i + \"_rscl\" for i in stars]].rename(\n",
    "    columns=lambda c: c.replace(\"_rscl\", \"\")\n",
    ")\n",
    "dataframe.columns.names = [\"star\"]\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will smooth the data by applying a rolling mean with a window of 100 periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count nan values\n",
    "\n",
    "But before since the dataset has some nan values, we will extract few statistics\n",
    "about the density of nan values in windows of size 100.\n",
    "\n",
    "It will be the occasion to show a usage of the `wax.modules.Buffer` module with the `format_outputs=False`\n",
    "option for the dataframe accessor `.wax.stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wax.modules import Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the `Buffer` module to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a10ccdefd2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/git/wax-ml/wax/accessors.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, module, params, state, rng, skip_first, format_dims)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         outputs = self.unroll_dataset(\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mmodule_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/git/wax-ml/wax/stream.py\u001b[0m in \u001b[0;36munroll_dataset\u001b[0;34m(self, module, params, state, rng, skip_first, encoders, dataset)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \"\"\"\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mnp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;31m# encode values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mnp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/git/wax-ml/wax/stream.py\u001b[0m in \u001b[0;36mtrace_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mstructure\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdataarray\u001b[0m \u001b[0mleaves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0mtime_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_time_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0mtime_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset_from_time_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mmaster_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_master_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/git/wax-ml/wax/stream.py\u001b[0m in \u001b[0;36mget_time_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_time_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;34m\"\"\" \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mtime_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_time_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mtime_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtime_coords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/git/wax-ml/wax/stream.py\u001b[0m in \u001b[0;36mget_dataset_time_coords\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     }\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime_coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "buffer, _ = dataframe.wax.stream(format_outputs=False).apply(lambda x: Buffer(100)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(buffer, jnp.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe the statistic of nans with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nan = jnp.isnan(buffer).sum(axis=1)\n",
    "pd.DataFrame(onp.array(count_nan)).stack().describe().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the rolling mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose a `min_periods` of 5 in order to keep at leas 75% of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataframe_mean, _ = dataframe.wax.stream().apply(\n",
    "    lambda x: RollingMean(100, min_periods=5)(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[:, \"008241079\"].plot()\n",
    "dataframe_mean.loc[:, \"008241079\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Dataset API\n",
    "\n",
    "Let's illustrate how to do the same rolling mean operation but using wax accessors on xarray `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from jax.tree_util import tree_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_mean, _ = dataset.wax.stream().apply(\n",
    "    partial(tree_map, lambda x: RollingMean(100, min_periods=5)(x)),\n",
    "    format_dims=[\"time\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Its much longer than with dataframe)\n",
    "\n",
    "TODO: This is an issue that we should solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"008241079\"].plot()\n",
    "dataset_mean[\"008241079\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With dataarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray = dataframe.to_xarray().to_array(\"star\").transpose(\"time\", \"star\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataarray_mean, _ = dataarray.wax.stream().apply(\n",
    "    lambda x: RollingMean(100, min_periods=5)(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Its much longer than with dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray.sel(star=\"008241079\").plot()\n",
    "dataarray_mean.sel(star=\"008241079\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "source": [
    "## Forecasting with Machine Learning\n",
    "\n",
    "We need two forecast in this data, if you look with attention you'll see micro holes and big holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import NamedTuple, Tuple, TypeVar\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "Pair = Tuple[T, T]\n",
    "\n",
    "\n",
    "class Pair(NamedTuple):\n",
    "    x: T\n",
    "    y: T\n",
    "\n",
    "\n",
    "class TrainSplit(NamedTuple):\n",
    "    train: T\n",
    "    validation: T\n",
    "\n",
    "\n",
    "gg.theme_set(gg.theme_bw())\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 18, 8\n",
    "fig, (ax, lax) = plt.subplots(ncols=2, gridspec_kw={\"width_ratios\": [4, 1]})\n",
    "dataframe.plot(ax=ax, title=\"raw data\")\n",
    "ax.legend(bbox_to_anchor=(0, 0, 1, 1), bbox_transform=lax.transAxes)\n",
    "lax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 18, 8\n",
    "fig, (ax, lax) = plt.subplots(ncols=2, gridspec_kw={\"width_ratios\": [4, 1]})\n",
    "dataframe_mean.plot(ax=ax, title=\"Smoothed data\")\n",
    "ax.legend(bbox_to_anchor=(0, 0, 1, 1), bbox_transform=lax.transAxes)\n",
    "lax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mean.stack().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wax.encode import Encoder\n",
    "\n",
    "\n",
    "def min_max_scaler(values: pd.DataFrame, output_format: str = \"dataframe\") -> Encoder:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(values)\n",
    "    index = values.index\n",
    "    columns = values.columns\n",
    "\n",
    "    def encode(dataframe: pd.DataFrame):\n",
    "        nonlocal index\n",
    "        nonlocal columns\n",
    "        index = dataframe.index\n",
    "        columns = dataframe.columns\n",
    "        array_normed = scaler.transform(dataframe)\n",
    "        if output_format == \"dataframe\":\n",
    "            return pd.DataFrame(array_normed, index, columns)\n",
    "        elif output_format == \"jax\":\n",
    "            return jnp.array(array_normed)\n",
    "        else:\n",
    "            return array_normed\n",
    "\n",
    "    def decode(array_scaled):\n",
    "        value = scaler.inverse_transform(array_scaled)\n",
    "        if output_format == \"dataframe\":\n",
    "            return pd.DataFrame(value, index, columns)\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    return Encoder(encode, decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = min_max_scaler(dataframe_mean)\n",
    "dataframe_normed = scaler.encode(dataframe_mean)\n",
    "assert (scaler.decode(dataframe_normed) - dataframe_mean).stack().abs().max() < 1.0e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_normed.stack().hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train / validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wax.modules import FillNanInf, Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def split_feature_target(dataframe, look_back=SEQ_LEN) -> Pair:\n",
    "    x, _ = dataframe.wax.stream(format_outputs=False).apply(\n",
    "        lambda x: FillNanInf()(Lag(1)(Buffer(look_back)(x)))\n",
    "    )\n",
    "    B, T, F = x.shape\n",
    "    x = x.transpose(1, 0, 2)\n",
    "\n",
    "    y, _ = dataframe.wax.stream(format_outputs=False).apply(\n",
    "        lambda x: FillNanInf()(Buffer(look_back)(x))\n",
    "    )\n",
    "    y = y.transpose(1, 0, 2)\n",
    "    return Pair(x, y)\n",
    "\n",
    "\n",
    "def split_feature_target(\n",
    "    dataframe,\n",
    "    look_back=SEQ_LEN,\n",
    "    stack=True,\n",
    "    shuffle=False,\n",
    "    min_periods_ratio: float = 0.8,\n",
    ") -> Pair:\n",
    "    x, _ = dataframe.wax.stream(format_outputs=False).apply(\n",
    "        lambda x: Lag(1)(Buffer(look_back)(x))\n",
    "    )\n",
    "    x = x.transpose(1, 0, 2)\n",
    "\n",
    "    y, _ = dataframe.wax.stream(format_outputs=False).apply(\n",
    "        lambda x: Buffer(look_back)(x)\n",
    "    )\n",
    "    y = y.transpose(1, 0, 2)\n",
    "\n",
    "    T, B, F = x.shape\n",
    "\n",
    "    if stack:\n",
    "        x = x.reshape(T, B * F, 1)\n",
    "        y = y.reshape(T, B * F, 1)\n",
    "\n",
    "    if shuffle:\n",
    "        rng = jax.random.PRNGKey(42)\n",
    "        idx = jnp.arange(x.shape[1])\n",
    "        idx = jax.random.shuffle(rng, idx)\n",
    "        x = x[:, idx]\n",
    "        y = y[:, idx]\n",
    "\n",
    "    if min_periods_ratio:\n",
    "        count_nan = jnp.isnan(x).sum(axis=0)\n",
    "        mask = count_nan < min_periods_ratio * T\n",
    "        idx = jnp.where(mask)\n",
    "        # print(\"count_nan = \", count_nan)\n",
    "        # print(\"B = \", B)\n",
    "        x = x[:, idx[0], :]\n",
    "        y = y[:, idx[0], :]\n",
    "        T, B, F = x.shape\n",
    "        # print(\"B = \", B)\n",
    "\n",
    "    # round Batch size to a power of to\n",
    "    B_round = int(2 ** jnp.floor(jnp.log2(B)))\n",
    "    x = x[:, :B_round, :]\n",
    "    y = y[:, :B_round, :]\n",
    "\n",
    "    # fillnan by zeros\n",
    "    fill_nan_inf = hk.transform(lambda x: FillNanInf()(x))\n",
    "    params = fill_nan_inf.init(None, jnp.full(x.shape, jnp.nan, x.dtype))\n",
    "    x = fill_nan_inf.apply(params, None, x)\n",
    "    y = fill_nan_inf.apply(params, None, y)\n",
    "\n",
    "    return Pair(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validation(dataframe, stars, train_size, look_back) -> TrainSplit:\n",
    "\n",
    "    # prepare scaler\n",
    "    dataframe_train = dataframe[stars].iloc[:train_size]\n",
    "    scaler = min_max_scaler(dataframe_train)\n",
    "\n",
    "    # prepare train data\n",
    "    dataframe_train_normed = scaler.encode(dataframe_train)\n",
    "    train = split_feature_target(dataframe_train_normed, look_back)\n",
    "\n",
    "    # prepare validation data\n",
    "    valid_size = len(dataframe[stars]) - train_size\n",
    "    valid_size = int(2 ** jnp.floor(jnp.log2(valid_size)))\n",
    "    valid_end = int(train_size + valid_size)\n",
    "    dataframe_valid = dataframe[stars].iloc[train_size:valid_end]\n",
    "    dataframe_valid_normed = scaler.encode(dataframe_valid)\n",
    "    valid = split_feature_target(dataframe_valid_normed, look_back)\n",
    "\n",
    "    return TrainSplit(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Look at star: {STAR}\")\n",
    "train, valid = split_train_validation(dataframe_normed, [STAR], TRAIN_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].shape, train[1].shape, valid[0].shape, valid[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE, VALID_SIZE = len(train.x), len(valid.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = hk.PRNGSequence(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot an observation/target pair.\n",
    "batch_plot = jax.random.choice(next(seq), len(train[0]))\n",
    "df = pd.DataFrame(\n",
    "    {\"x\": train[0][:, batch_plot, 0], \"y\": train[1][:, batch_plot, 0]}\n",
    ").reset_index()\n",
    "df = pd.melt(df, id_vars=[\"index\"], value_vars=[\"x\", \"y\"])\n",
    "plot = (\n",
    "    gg.ggplot(df)\n",
    "    + gg.aes(x=\"index\", y=\"value\", color=\"variable\")\n",
    "    + gg.geom_line()\n",
    "    + gg.scales.scale_y_log10()\n",
    ")\n",
    "_ = plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"An iterator over a numpy array, revealing batch_size elements at a time.\"\"\"\n",
    "\n",
    "    def __init__(self, xy: Pair, batch_size: int):\n",
    "        self._x, self._y = xy\n",
    "        self._batch_size = batch_size\n",
    "        self._length = self._x.shape[1]\n",
    "        self._idx = 0\n",
    "        if self._length % batch_size != 0:\n",
    "            msg = \"dataset size {} must be divisible by batch_size {}.\"\n",
    "            raise ValueError(msg.format(self._length, batch_size))\n",
    "\n",
    "    def __next__(self) -> Pair:\n",
    "        start = self._idx\n",
    "        end = start + self._batch_size\n",
    "        x, y = self._x[:, start:end], self._y[:, start:end]\n",
    "        if end >= self._length:\n",
    "            end = end % self._length\n",
    "            assert end == 0  # Guaranteed by ctor assertion.\n",
    "        self._idx = end\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train, BATCH_SIZE)\n",
    "valid_ds = Dataset(valid, BATCH_SIZE)\n",
    "del train, valid  # Don't leak temporaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZGw5Jdvjmqh"
   },
   "source": [
    "### Training an LSTM\n",
    "\n",
    "To train the LSTM, we define a Haiku function which unrolls the LSTM over the input sequence, generating predictions for all output values. The LSTM always starts with its initial state at the start of the sequence.\n",
    "\n",
    "The Haiku function is then transformed into a pure function through `hk.transform`, and is trained with Adam on an L2 prediction loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wax.compile import jit_init_apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_ds)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nacnTj5ejIK5"
   },
   "outputs": [],
   "source": [
    "def unroll_net(seqs: jnp.ndarray):\n",
    "    \"\"\"Unrolls an LSTM over seqs, mapping each output to a scalar.\"\"\"\n",
    "    # seqs is [T, B, F].\n",
    "    core = hk.LSTM(32)\n",
    "    batch_size = seqs.shape[1]\n",
    "    outs, state = hk.dynamic_unroll(core, seqs, core.initial_state(batch_size))\n",
    "    # We could include this Linear as part of the recurrent core!\n",
    "    # However, it's more efficient on modern accelerators to run the linear once\n",
    "    # over the entire sequence than once per sequence element.\n",
    "    return hk.BatchApply(hk.Linear(1))(outs), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nacnTj5ejIK5"
   },
   "outputs": [],
   "source": [
    "model = jit_init_apply(hk.transform(unroll_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nacnTj5ejIK5"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_ds: Dataset, valid_ds: Dataset, max_iterations: int = -1\n",
    ") -> hk.Params:\n",
    "    \"\"\"Initializes and trains a model on train_ds, returning the final params.\"\"\"\n",
    "    rng = jax.random.PRNGKey(428)\n",
    "    opt = optax.adam(1e-3)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss(params, x, y):\n",
    "        pred, _ = model.apply(params, None, x)\n",
    "        return jnp.mean(jnp.square(pred - y))\n",
    "\n",
    "    @jax.jit\n",
    "    def update(step, params, opt_state, x, y):\n",
    "        l, grads = jax.value_and_grad(loss)(params, x, y)\n",
    "        grads, opt_state = opt.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, grads)\n",
    "        return l, params, opt_state\n",
    "\n",
    "    # Initialize state.\n",
    "    sample_x, _ = next(train_ds)\n",
    "    params = model.init(rng, sample_x)\n",
    "    opt_state = opt.init(params)\n",
    "\n",
    "    step = 0\n",
    "    records = defaultdict(list)\n",
    "\n",
    "    def _format_results(records):\n",
    "        records = {key: jnp.stack(l) for key, l in records.items()}\n",
    "        return records\n",
    "\n",
    "    with tqdm() as pbar:\n",
    "        while True:\n",
    "            if step % 100 == 0:\n",
    "                x, y = next(valid_ds)\n",
    "                valid_loss = loss(params, x, y)\n",
    "                # print(\"Step {}: valid loss {}\".format(step, valid_loss))\n",
    "                records[\"step\"].append(step)\n",
    "                records[\"valid_loss\"].append(valid_loss)\n",
    "\n",
    "            try:\n",
    "                x, y = next(train_ds)\n",
    "            except StopIteration:\n",
    "                return params, _format_results(records)\n",
    "            train_loss, params, opt_state = update(step, params, opt_state, x, y)\n",
    "            if step % 100 == 0:\n",
    "                # print(\"Step {}: train loss {}\".format(step, train_loss))\n",
    "                records[\"train_loss\"].append(train_loss)\n",
    "\n",
    "            step += 1\n",
    "            pbar.update()\n",
    "            if max_iterations > 0 and step >= max_iterations:\n",
    "                return params, _format_results(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AssgDctokbl5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trained_params, records = train_model(train_ds, valid_ds, TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "losses = pd.DataFrame(records)\n",
    "df = pd.melt(losses, id_vars=[\"step\"], value_vars=[\"train_loss\", \"valid_loss\"])\n",
    "plot = (\n",
    "    gg.ggplot(df)\n",
    "    + gg.aes(x=\"step\", y=\"value\", color=\"variable\")\n",
    "    + gg.geom_line()\n",
    "    + gg.scales.scale_y_log10()\n",
    ")\n",
    "_ = plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yr7jrOL3ki-b"
   },
   "source": [
    "### Sampling\n",
    "\n",
    "The point of training models is so that they can make predictions! How can we generate predictions with the trained model?\n",
    "\n",
    "If we're allowed to feed in the ground truth, we can just run the original model's `apply` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2qETEqXLT1N"
   },
   "outputs": [],
   "source": [
    "def plot_samples(truth: np.ndarray, prediction: np.ndarray) -> gg.ggplot:\n",
    "    assert truth.shape == prediction.shape\n",
    "    df = pd.DataFrame(\n",
    "        {\"truth\": truth.squeeze(), \"predicted\": prediction.squeeze()}\n",
    "    ).reset_index()\n",
    "    df = pd.melt(df, id_vars=[\"index\"], value_vars=[\"truth\", \"predicted\"])\n",
    "    plot = (\n",
    "        gg.ggplot(df) + gg.aes(x=\"index\", y=\"value\", color=\"variable\") + gg.geom_line()\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOuK1egilGD0"
   },
   "outputs": [],
   "source": [
    "# Grab a sample from the validation set.\n",
    "sample_x, _ = next(valid_ds)\n",
    "sample_x = sample_x[:, :1]  # Shrink to batch-size 1.\n",
    "\n",
    "# Generate a prediction, feeding in ground truth at each point as input.\n",
    "predicted, _ = model.apply(trained_params, None, sample_x)\n",
    "\n",
    "plot = plot_samples(sample_x[1:], predicted[:-1])\n",
    "plot.draw()\n",
    "del sample_x, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run autoregressively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDyGshz_lwrM"
   },
   "source": [
    "If we can't feed in the ground truth (because we don't have it), we can also run the model autoregressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg8oQ75Ulvld"
   },
   "outputs": [],
   "source": [
    "def autoregressive_predict(\n",
    "    trained_params: hk.Params,\n",
    "    context: jnp.ndarray,\n",
    "    seq_len: int,\n",
    "):\n",
    "    \"\"\"Given a context, autoregressively generate the rest of a sine wave.\"\"\"\n",
    "    ar_outs = []\n",
    "    context = jax.device_put(context)\n",
    "    times = range(seq_len - context.shape[0])\n",
    "    for _ in times:\n",
    "        full_context = jnp.concatenate([context] + ar_outs)\n",
    "        outs, _ = jax.jit(model.apply)(trained_params, None, full_context)\n",
    "        # Append the newest prediction to ar_outs.\n",
    "        ar_outs.append(outs[-1:])\n",
    "    # Return the final full prediction.\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg8oQ75Ulvld"
   },
   "outputs": [],
   "source": [
    "sample_x, _ = next(valid_ds)\n",
    "context_length = SEQ_LEN // 8\n",
    "# Cut the batch-size 1 context from the start of the sequence.\n",
    "context = sample_x[:context_length, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg8oQ75Ulvld"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# We can reuse params we got from training for inference - as long as the\n",
    "# declaration order is the same.\n",
    "predicted = autoregressive_predict(trained_params, context, SEQ_LEN)\n",
    "\n",
    "plot = plot_samples(sample_x[1:, :1], predicted)\n",
    "plot += gg.geom_vline(xintercept=len(context), linetype=\"dashed\")\n",
    "plot.draw()\n",
    "del predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGkr2gf2oALo"
   },
   "source": [
    "#### Sharing parameters with a different function.\n",
    "\n",
    "Unfortunately, this is a bit slow - we're doing O(N^2) computation for a sequence of length N.\n",
    "\n",
    "It'd be better if we could do the autoregressive sampling all at once - but we need to write a new Haiku function for that.\n",
    "\n",
    "We're in luck - if the Haiku module names match, the same parameters can be used for multiple Haiku functions.\n",
    "\n",
    "This can be achieved through a combination of two techniques:\n",
    "\n",
    "1. If we manually give a unique name to a module, we can ensure that the parameters are directed to the right places.\n",
    "2. If modules are instantiated in the same order, they'll have the same names in different functions.\n",
    "\n",
    "Here, we rely on method #2 to create a fast autoregressive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdKcHr6_n_ba"
   },
   "outputs": [],
   "source": [
    "def fast_autoregressive_predict_fn(context, seq_len):\n",
    "    \"\"\"Given a context, autoregressively generate the rest of a sine wave.\"\"\"\n",
    "    core = hk.LSTM(32)\n",
    "    dense = hk.Linear(1)\n",
    "    state = core.initial_state(context.shape[1])\n",
    "    # Unroll over the context using `hk.dynamic_unroll`.\n",
    "    # As before, we `hk.BatchApply` the Linear for efficiency.\n",
    "    context_outs, state = hk.dynamic_unroll(core, context, state)\n",
    "    context_outs = hk.BatchApply(dense)(context_outs)\n",
    "\n",
    "    # Now, unroll one step at a time using the running recurrent state.\n",
    "    ar_outs = []\n",
    "    x = context_outs[-1]\n",
    "    times = range(seq_len - context.shape[0])\n",
    "    for _ in times:\n",
    "        x, state = core(x, state)\n",
    "        x = dense(x)\n",
    "        ar_outs.append(x)\n",
    "    return jnp.concatenate([context_outs, jnp.stack(ar_outs)])\n",
    "\n",
    "\n",
    "fast_ar_predict = hk.transform(fast_autoregressive_predict_fn)\n",
    "fast_ar_predict = jax.jit(fast_ar_predict.apply, static_argnums=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdKcHr6_n_ba",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reuse the same context from the previous cell.\n",
    "predicted = fast_ar_predict(trained_params, None, context, SEQ_LEN)\n",
    "\n",
    "# The plots should be equivalent!\n",
    "plot = plot_samples(sample_x[1:, :1], predicted[:-1])\n",
    "plot += gg.geom_vline(xintercept=len(context), linetype=\"dashed\")\n",
    "_ = plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S0tkPXGrU3a",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%timeit autoregressive_predict(trained_params, context, SEQ_LEN)\n",
    "%timeit fast_ar_predict(trained_params, None, context, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Train all stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validation_date(dataframe, stars, date, look_back) -> TrainSplit:\n",
    "    train_size = len(dataframe.loc[:date])\n",
    "    return split_train_validation(dataframe, stars, train_size, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train, valid = split_train_validation_date(dataframe_normed, stars, TRAIN_DATE, SEQ_LEN)\n",
    "TRAIN_SIZE = train[0].shape[1]\n",
    "print(f\"TRAIN_SIZE = {TRAIN_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].shape, train[1].shape, valid[0].shape, valid[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train, BATCH_SIZE)\n",
    "valid_ds = Dataset(valid, BATCH_SIZE)\n",
    "del train, valid  # Don't leak temporaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trained_params, records = train_model(train_ds, valid_ds, TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "losses = pd.DataFrame(records)\n",
    "df = pd.melt(losses, id_vars=[\"step\"], value_vars=[\"train_loss\", \"valid_loss\"])\n",
    "plot = (\n",
    "    gg.ggplot(df)\n",
    "    + gg.aes(x=\"step\", y=\"value\", color=\"variable\")\n",
    "    + gg.geom_line()\n",
    "    + gg.scales.scale_y_log10()\n",
    ")\n",
    "_ = plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a sample from the validation set.\n",
    "sample_x, _ = next(valid_ds)\n",
    "sample_x = sample_x[:, :1]  # Shrink to batch-size 1.\n",
    "\n",
    "# Generate a prediction, feeding in ground truth at each point as input.\n",
    "predicted, _ = model.apply(trained_params, None, sample_x)\n",
    "\n",
    "plot = plot_samples(sample_x[1:], predicted[:-1])\n",
    "plot.draw()\n",
    "del sample_x, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run autoregressively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_x, _ = next(valid_ds)\n",
    "context_length = SEQ_LEN // 8\n",
    "# Cut the batch-size 1 context from the start of the sequence.\n",
    "context = sample_x[:context_length, :1]\n",
    "\n",
    "# Reuse the same context from the previous cell.\n",
    "predicted = fast_ar_predict(trained_params, None, context, SEQ_LEN)\n",
    "\n",
    "# The plots should be equivalent!\n",
    "plot = plot_samples(sample_x[1:, :1], predicted[:-1])\n",
    "plot += gg.geom_vline(xintercept=len(context), linetype=\"dashed\")\n",
    "_ = plot.draw()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
